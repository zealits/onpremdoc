=== Sheet 1: Summary ===
('Document Processing Pipeline - Summary', None)
(None, None)
('Total Steps:', 30)
('Phase 1: PDF Upload & Processing', 'Steps 1-6')
('Phase 2: Vectorization', 'Steps 7-19')
('Phase 3: Query & Retrieval', 'Steps 20-29')
('Phase 4: Page Summarization', 'Step 30')
(None, None)
('Key Technologies:', None)
('- FastAPI', 'Web framework')
('- Docling', 'PDF to markdown conversion')
('- Ollama', 'LLM and embeddings (nomic-embed-text:v1.5, llama3.1:8b)')
('- Chroma', 'Vector database')
('- NetworkX', 'Graph structure')
('- LangGraph', 'State machine workflow')
(None, None)
('Key Algorithms:', None)
('- Vector similarity search (L2 distance)', None)
('- Graph traversal (BFS-like expansion)', None)
('- LLM-based re-ranking', None)
('- LLM-based summarization', None)
('- Table detection and fixing', None)
('- Hierarchical structure extraction', None)

=== Sheet 2: Pipeline Steps ===
('Step #', 'Step Name', 'Description', 'Module/File', 'Models & Technologies', 'Algorithms & Methods', 'Key Functions', 'Input', 'Output')
(None, None, 'User uploads PDF file via FastAPI endpoint. File is saved to document-specific folder with unique UUID.', None, None, None, None, 'PDF file (UploadFile)', 'Saved PDF file, document_id, ProcessPDFResponse')
(None, None, 'Background task processes PDF: converts to markdown, fixes tables, extracts page mapping.', None, None, None, None, 'PDF file path', 'Markdown file (.md), Page mapping JSON (_page_mapping.json)')
(None, None, 'Docling converts PDF to structured markdown with page break markers. Preserves document structure.', None, None, None, None, 'PDF file', 'Raw markdown with page break markers (<!-- page break -->)')
(None, None, 'Fixes heading hierarchy using TOC/bookmarks. Corrects heading levels for proper document structure.', None, None, None, None, 'Docling document object', 'Document with corrected heading hierarchy')
(None, None, 'Detects markdown tables, fixes formatting issues (separators, headers, grouping), handles complex table structures.', None, None, None, None, 'Markdown text with tables', 'Fixed markdown with properly formatted tables')
(None, None, 'Extracts page boundaries from markdown with page break markers. Maps each line to page number.', None, None, None, None, 'Markdown with page break markers', 'Page mapping JSON: {line_to_page, page_boundaries, total_pages}')
(None, None, 'API endpoint triggers vectorization workflow. Creates initial state for LangGraph workflow.', None, None, None, None, 'document_id', 'VectorizerState with markdown_file path')
(None, None, 'Loads markdown file and page mapping. Parses markdown into chunks with structure awareness.', None, None, None, None, 'Markdown file path, page mapping JSON', 'List of Document chunks, document structure dictionary')
(None, None, 'Extracts hierarchical structure: sections, headers, tables. Builds section hierarchy tree.', None, None, None, None, 'Markdown content', 'Structure dict: {sections, headers, tables}')
(None, None, 'Splits markdown into chunks (2000 chars, 150 overlap). Filters empty chunks, removes duplicates. Adds metadata.', None, None, None, None, 'Markdown content, structure, page mapping', 'List of Document chunks with metadata (heading, section_path, page_number, etc.)')
(None, None, 'Initializes Ollama LLM and embeddings models. Sets up vector store (Chroma) and document graph.', None, None, None, None, 'Model names, base URL', 'Initialized LLM, embeddings, vector store, DocumentGraph')
(None, None, 'Builds knowledge graph: adds section nodes, creates parent-child relationships between sections.', None, None, None, None, 'Document structure (sections)', 'Graph with section nodes and hierarchical edges')
(None, None, 'Classifies each page using LLM based on content. Generates descriptive labels (1-4 words) for each page.', None, None, None, None, 'Chunks grouped by page, page mapping', 'Dictionary: {page_number: classification_label}')
(None, None, 'For each chunk: generates summary using LLM, creates embedding, adds to vector store, adds to graph.', None, None, None, None, 'Chunk content', 'Embedded chunk in vector store, chunk node in graph, JSON mapping entry')
(None, None, 'Generates one-line summary for each chunk using LLM. Token-limited to 500 tokens.', None, None, None, None, 'Chunk content (max 2000 chars)', 'One-line summary string')
(None, None, 'Generates vector embeddings for each chunk using nomic-embed-text model. Truncates if exceeds limits.', None, None, None, None, 'Chunk content (max 2000 chars, 1500 tokens)', 'Vector embedding (stored in Chroma)')
(None, None, 'Adds chunk nodes to graph. Creates edges: chunk→section (belongs_to), chunk→page (on_page), chunk→chunk (follows).', None, None, None, None, 'Chunk metadata (section_path, page_number, prev/next chunk IDs)', 'Graph nodes and edges for chunks')
(None, None, "Computes similarity between chunks using vector search. Adds 'similar_to' edges for chunks above threshold (0.50).", None, None, None, None, 'Chunk embeddings', 'Graph edges with similarity scores (similar_to relation)')
(None, None, 'Saves document graph to JSON, saves vector mapping to JSON, persists Chroma vector database.', None, None, None, None, 'DocumentGraph, JSON mapping, vector store', 'Graph JSON file, vector mapping JSON file, persisted Chroma DB')
(None, None, 'User submits query via API. System loads agent resources for document.', None, None, None, None, 'Query string, document_id', 'Initialized AgentState')
(None, None, 'Loads vector store, document graph, chunks, LLM. Initializes page summarization agent if available.', None, None, None, None, 'Vector DB path, mapping file, graph file', 'Loaded vector store, graph, chunks, LLM, page agent')
(None, None, 'Classifies query as page summary request or normal retrieval. Uses pattern matching + LLM classification.', None, None, None, None, 'User query', 'is_page_summary (bool), page_number (optional)')
(None, None, 'Performs vector similarity search to find top-k (20) most relevant chunks. Converts L2 distance to similarity score.', None, None, None, None, 'Query string', 'Seed chunk IDs, similarity scores')
(None, None, 'Expands from top seed chunks (top 5) via graph edges: sections, adjacent chunks, similar chunks. Max 15 expansion.', None, None, None, None, 'Seed chunk IDs', 'Expanded chunk IDs (via graph edges)')
(None, None, 'Re-ranks retrieved chunks by relevance to query using LLM. Scores 0.0-1.0. Selects top 25 chunks.', None, None, None, None, 'Query, retrieved chunks (max 30)', 'Re-ranked chunks (top 25), rerank scores')
(None, None, 'Analyzes retrieved chunks to determine if more information is needed. Generates new query if needed.', None, None, None, None, 'Query, retrieved chunks (top 12)', 'Analysis text, needs_more_info (bool), new_query (optional)')
(None, None, 'If more info needed, performs second vector search with new query. Expands via graph. Re-ranks results.', None, None, None, None, 'New query, existing chunk IDs (to avoid duplicates)', 'Additional retrieved chunks')
(None, None, 'Generates comprehensive answer from all retrieved chunks using LLM. Uses top 25 chunks as context.', None, None, None, None, 'Query, retrieved chunks (top 25), rerank scores', 'Final answer text')
(None, None, 'Formats response with answer, chunk details, retrieval stats, debug info. Returns to API client.', None, None, None, None, 'Final answer, chunks, stats', 'QueryResponse JSON')
(None, None, 'If query is page summary request, uses PageSummarizationAgent to generate page-level summary.', None, None, None, None, 'Page number', 'Page summary with key points, sections, classification')
