# Token Usage Report — 2026-02-03

**Document:** `HDFC-Life-Cancer-Care-101N106V04-Policy-Document.pdf`  
**Document ID:** `628f2c45-df16-4675-89d1-870c0758e4d7`

---

## At a glance

| Metric | Value |
|--------|--------|
| **Total pipeline steps** | 10 |
| **Total tokens (this session)** | **57,052** |
| **Input tokens** | 37,878 |
| **Output tokens** | 384 |
| **Embedding tokens** | 18,790 |
| **Model** | Ollama (local) |
| **Estimated cost** | zero (on-premise) |

---

## 1. Upload and processing (no tokens)

| Step | Time (UTC) | Details |
|------|------------|--------|
| **PDF upload** | 10:48:50 | File size: **526 KB** · File: `HDFC-Life-Cancer-Care-101N106V04-Policy-Document.pdf` |
| **PDF to Markdown** | 10:49:25 | **14 pages** converted to markdown and structure |

No token usage: 0 input, 0 output, 0 embedding tokens. These steps use document processing only.

---

## 2. Vectorization (one-time, full document)

| Step | Time (UTC) | Input tokens | Output tokens | Embedding tokens | Total |
|------|------------|--------------|---------------|------------------|--------|
| **Vectorization** | 10:58:33 | 29,189 | 0 | 18,761 | **47,950** (5 cents on average) |

- **32 chunks** processed (summaries + embeddings).
- **0** chunks truncated.
- **Models:** nomic-embed-text (embeddings) + llama3.1:8b (chunk summaries).

This is the one-time step that embeds the whole PDF and builds the graph. It is included in this report.

---

## 3. Query and retrieval (one query)

One user query was run. Breakdown by sub-step:

| Step | Input tokens | Output tokens | Embedding tokens | Total |
|------|--------------|---------------|------------------|--------|
| Query classification (LLM) | 60 | 85 | — | 145 |
| Initial retrieval (embed query) | — | — | 13 | 13 |
| Chunk analysis (LLM) | 2,134 | 45 | — | 2,179 |
| Second retrieval (embed follow-up) | — | — | 16 | 16 |
| Generate answer (LLM) | 6,495 | 254 | — | 6,749 |
| **Query total** | **8,689** | **384** | **29** | **9,102** |

- **Input tokens:** Prompt and context sent to the LLM (e.g. question and retrieved chunks).
- **Output tokens:** Text generated by the LLM (e.g. classification, analysis, final answer).
- **Embedding tokens:** Text sent to the embedding model (user query and optional follow-up query only; not the full document).

---

## How to read this

- **Upload / PDF processing:** No token cost; shows file size and page count.
- **Vectorization:** One-time cost to embed all chunks and generate summaries. Included above; large share of total tokens.
- **Retrieval:** Per-query cost (classify, retrieve, analyze, answer). Totals above are for that single query.
- **Cost:** With Ollama running locally, monetary cost is zero. These token counts show **volume**; if you switched to a cloud API, you could multiply by your provider's price per 1K tokens to estimate cost.

---

Report generated from `usage_2026-02-03.jsonl`.
