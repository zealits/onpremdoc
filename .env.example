# Copy to .env and set values. Do not commit .env (it may contain secrets).

# ---------------------------------------------------------------------------
# Inference provider: ollama (local) or huggingface (serverless)
# ---------------------------------------------------------------------------
# INFERENCE_PROVIDER=ollama
# INFERENCE_PROVIDER=huggingface

# ---------------------------------------------------------------------------
# Ollama (used when INFERENCE_PROVIDER=ollama or unset)
# ---------------------------------------------------------------------------
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:v1.5
# OLLAMA_LLM_MODEL=llama3.1:8b

# ---------------------------------------------------------------------------
# Hugging Face (used when INFERENCE_PROVIDER=huggingface)
# Get token: https://huggingface.co/settings/tokens (needs Inference Providers permission)
# ---------------------------------------------------------------------------
# HUGGINGFACEHUB_API_TOKEN=your_hf_token_here
# HF_TOKEN=your_hf_token_here

# Optional: override embedding/LLM models (HF)
# HF_EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
# HF_LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
